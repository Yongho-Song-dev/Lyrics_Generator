{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 노래 작사를 해주는 인공지능을 만들어 보자.\n",
    "\n",
    "- 필요한 데이터 준비\n",
    " - kaggle에 있는 Song Lyrics 데이터셋 사용 \n",
    "\n",
    "Lytics data : [Song Lyrics](https://www.kaggle.com/paultimothymooney/poetry/data \"kaggle song lyrics dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 크기: 187088\n",
      "Examples:\n",
      " ['I bought my first key from my baby momma brother', 'I bought my first key', 'Bought my bought my first key']\n"
     ]
    }
   ],
   "source": [
    "# glob로 파일을 읽어와서 문장 단위로 저장\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.random.set_seed(21)\n",
    "txt_file_path = os.getenv('HOME')+'/aiffel/lyricist/data/lyrics/*' # * 옵션 : 모든 파일, 디렉토리 읽기\n",
    "# glob 사용시 원시 문자열 경로여야 한다.\n",
    "\n",
    "txt_list = glob.glob(txt_file_path)  # path에 ( * )가 주어졌으므로 모든 파일, 디렉토리 읽기\n",
    "                                     # 해당 위치에 있는 모든 .txt 파일을 읽어온다.\n",
    "\n",
    "raw_corpus = []\n",
    "\n",
    "# 여러개의 txt 파일을 모두 읽어서 raw_corpus 에 담습니다.\n",
    "for txt_file in txt_list:\n",
    "    with open(txt_file, \"r\") as f:\n",
    "        raw = f.read().splitlines()  # 문장 단위로 읽어오기\n",
    "        raw_corpus.extend(raw)      # 읽어온 문장 저장\n",
    "\n",
    "print(\"데이터 크기:\", len(raw_corpus))\n",
    "print(\"Examples:\\n\", raw_corpus[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.data.Dataset 객체로 변환하기 위한 데이터 정제\n",
    "- 문장을 인자로 받고 re모듈의 정규 표현식을 통한 필터링을 진행한 후, 일정한 기준으로 문장을 쪼갠다.\n",
    "\n",
    "\n",
    "- 이러한 과정을 **토큰화(Tokenize)**라고 한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('<start> this is a sample sentence . <end>', 8)\n",
      "토큰(단어)의 개수  :  8\n"
     ]
    }
   ],
   "source": [
    "import re # 정규 표현식위한 모듈\n",
    "\n",
    "def preprocess_sentence(sentence): # 문장을 인자로 받고 정제된 문장을 반환하게 한다.\n",
    "    sentence = sentence .lower().strip()  # 소문자로 바꾼 후 양쪽 공백 삭제\n",
    "    \n",
    "    # 문장부호, 대소문자, 특수문자에 대해 필터링 과정\n",
    "    # 아래 3단계를 거쳐 sentence는 스페이스 1개를 delimeter로 하는 소문자 단어 시퀀스로 변환된다.\n",
    "    \n",
    "    sentence = re.sub(r\"([?.!,¿])\", r\" \\1 \", sentence)        # 패턴의 특수문자를 만나면 특수문자 양쪽에 공백을 추가\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)                  # 공백 패턴을 만나면 스페이스 1개로 치환\n",
    "    sentence = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", sentence)  # a-zA-Z?.!,¿ 패턴을 제외한 모든 문자(공백문자까지도)를 스페이스 1개로 치환\n",
    "    \n",
    "    sentence = sentence.strip() #  위에 필터링 과정에서 생긴 \" \"을 제거해 준다.\n",
    "    \n",
    "    #token_len = sentence.split(' ') # 스페이스 단위로 구분해서 토큰의 개수가 몇개인지 반환\n",
    "\n",
    "    \n",
    "    sentence ='<start> ' + sentence + ' <end>'  # 시작 끝 지정\n",
    "    # 문장 앞뒤로 <start>와 <end>를 단어처럼 붙여 줍니다\n",
    "    \n",
    "    token_len = sentence.split(' ') # 스페이스 단위로 구분해서 토큰의 개수가 몇개인지 반환\n",
    "    \n",
    "    return sentence, len(token_len)\n",
    "\n",
    "\n",
    "print(preprocess_sentence(\" : This @_is  ^^ a ;;;sample ___       sentence.\"))   # 문장이 어떻게 필터링되는지 확인\n",
    "print(\"토큰(단어)의 개수  : \", preprocess_sentence(\" : This @_is  ^^ a ;;;sample ___       sentence.\")[1] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sentence가 주어지면 문장부호, 대소문자, 특수문자에 대한 필터링을 하는 함수이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문장 자체에 필터링만 하는것이 아닌 문장의 길이에 대해서도 정제를 해주어야 한다.\n",
    "- 아예 공백인 문장이거나, 문장의 길이가 너무 길어서 Padding 할 때 다른 문장에 영향을 끼칠때\n",
    "\n",
    "\n",
    "####  문장의 길이가 0인 경우와 토큰의 개수가 많은 경우 학습데이터에서 제외를 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<start> i bought my first key from my baby momma brother <end>',\n",
       " '<start> i bought my first key <end>',\n",
       " '<start> bought my bought my first key <end>',\n",
       " '<start> i bought my first key from my baby momma brother <end>',\n",
       " '<start> i bought my first key <end>',\n",
       " '<start> bought my bought my first key <end>',\n",
       " '<start> yeah hustling on my city streets <end>',\n",
       " '<start> inand we was getting em like for twenty five <end>',\n",
       " '<start> colombian connect homey we was getting fly <end>',\n",
       " '<start> we on the grind and our nuts got bigga <end>']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = []\n",
    "\n",
    "for sentence in raw_corpus: \n",
    "    if len(sentence) <= 1: continue\n",
    "    #if sentence[-1] == \":\": continue\n",
    "    # 빈 문장인 경우 제외 \n",
    "    \n",
    "    preProcess_sentence = preprocess_sentence(sentence) \n",
    "    # preProcess_sentence : return 문장, 토큰 개수[문장을 이루는 단어의 개수]\n",
    "    \n",
    "    if preProcess_sentence[1] > 15 : continue  \n",
    "    # 토큰의 개수가 15개 이상인 경우 학습데이터에서 제거\n",
    "    # 많이 긴 문장이 있는 경우 다른 데이터들을 Padding할 때 과도한 <pad>를 갖게 하므로 학습 데이터에서 제외한다.\n",
    "    \n",
    "    corpus.append(preProcess_sentence[0]) # sentence 데이터만 넣기\n",
    "         \n",
    "corpus[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 토큰화된 데이터를 숫자 데이터인 tensor로 변환   \n",
    "**벡터화(vectorize)**\n",
    "\n",
    "- 정제된 데이터를 토큰화하고, 단어 사전(vocabulary)을 만들어주며, 데이터를 숫자로 변환\n",
    "\n",
    "- 이 과정을 **벡터화(vectorize)** 라 하며, 숫자로 변환된 데이터를 **텐서(tensor)** 라고 한다.\n",
    "\n",
    "\n",
    "- 텐서란 간단하게 몇 차원 배열인가를 의미한다.\n",
    "  - 3차원 이상부터 3D-tensor, 4D-tensor, 5D-tensor...로 부른다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  2   4 593 ...   0   0   0]\n",
      " [  2   4 593 ...   0   0   0]\n",
      " [  2 593  13 ...   0   0   0]\n",
      " ...\n",
      " [  2   9 363 ...   0   0   0]\n",
      " [  2   9 363 ...   0   0   0]\n",
      " [  2   9 363 ...   0   0   0]] <keras_preprocessing.text.Tokenizer object at 0x7ff8f069c590>\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "#tf.random.set_seed(21)\n",
    "tf.random.set_seed(25)\n",
    "def tokenize(corpus):\n",
    "    # 텐서플로우에서 제공하는 Tokenizer 패키지를 생성\n",
    "    # num_words=14000\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "        num_words=13000,  # 전체 단어의 개수 \n",
    "        filters=' ',    # 별도의 전처리 로직을 추가할 수 있습니다.\n",
    "        oov_token=\"<unk>\"  # out-of-vocabulary, 사전에 없었던 단어는 어떤 토큰으로 대체할지\n",
    "    )\n",
    "    tokenizer.fit_on_texts(corpus)   # 우리가 구축한 corpus로부터 Tokenizer가 사전을 자동구축하게 됩니다.\n",
    "\n",
    "    # 이후 tokenizer를 활용하여 모델에 입력할 데이터셋을 구축하게 됩니다.\n",
    "    tensor = tokenizer.texts_to_sequences(corpus)   # tokenizer는 구축한 사전으로부터 corpus를 해석해 Tensor로 변환합니다.\n",
    "\n",
    "    # 입력 데이터의 시퀀스 길이를 일정하게 맞추기 위한 padding  메소드를 제공합니다.\n",
    "    # maxlen의 디폴트값은 None입니다. 이 경우 corpus의 가장 긴 문장을 기준으로 시퀀스 길이가 맞춰집니다.\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')  \n",
    "\n",
    "    print(tensor,tokenizer)\n",
    "    return tensor, tokenizer\n",
    "\n",
    "tensor, tokenizer = tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  2   4 593  13 247 773  73  13  52 774 583   3   0   0   0]\n",
      " [  2   4 593  13 247 773   3   0   0   0   0   0   0   0   0]\n",
      " [  2 593  13 593  13 247 773   3   0   0   0   0   0   0   0]\n",
      " [  2   4 593  13 247 773  73  13  52 774 583   3   0   0   0]\n",
      " [  2   4 593  13 247 773   3   0   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "# 텐서 데이터 확인 10행 15열\n",
    "# 확인해보니 15개의 토큰을 가진 데이터가 적어서 \n",
    "# 앞에서 15개 초과 토큰 단위로 잘 자른것을 알 수 있다. \n",
    "print(tensor[:5, :16]) # 첫문장은 <start>이니 15가아닌 16으로 해야한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : <unk>\n",
      "2 : <start>\n",
      "3 : <end>\n",
      "4 : i\n",
      "5 : ,\n",
      "6 : the\n",
      "7 : you\n",
      "8 : and\n",
      "9 : a\n",
      "10 : to\n"
     ]
    }
   ],
   "source": [
    "# 단언사전 내부 확인\n",
    "for idx in tokenizer.index_word:\n",
    "    print(idx, \":\", tokenizer.index_word[idx])\n",
    "\n",
    "    if idx >= 10: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156097, 15)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# () 포함 \n",
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156192, 15)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 준비된 데이터셋을 train/test 데이터 셋으로 분리\n",
    "train_test_split() 함수 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2,   4, 593, ...,   0,   0,   0],\n",
       "       [  2,   4, 593, ...,   0,   0,   0],\n",
       "       [  2, 593,  13, ...,   0,   0,   0],\n",
       "       ...,\n",
       "       [  2,   9, 363, ...,   0,   0,   0],\n",
       "       [  2,   9, 363, ...,   0,   0,   0],\n",
       "       [  2,   9, 363, ...,   0,   0,   0]], dtype=int32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.shape\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Train: (124953, 14)\n",
      "Target Train: (124953, 14)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "# tensor에서 마지막 토큰을 잘라내서 train을 생성합니다.\n",
    "# 마지막 토큰은 <end>가 아니라 <pad>일 가능성이 높습니다.\n",
    "# tensor에서 <start>를 잘라내서 val 문장 생성\n",
    "\n",
    "enc_train, enc_val, dec_train, dec_val = train_test_split(tensor[:, :-1],tensor[:, 1:],\n",
    "                                                          test_size=0.2, shuffle=True)\n",
    "\n",
    "print(\"Source Train:\", enc_train.shape)\n",
    "print(\"Target Train:\", dec_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31239, 14)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(124953, 14)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(124953, 14)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31239, 14)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "-  데이터셋을 텐서 형태로 생성해 두었기에, tf.data.Dataset.from_tensor_slices() 메소드를 이용해 tf.data.Dataset객체를 생성한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset :  <BatchDataset shapes: ((128, 14), (128, 14)), types: (tf.int32, tf.int32)>\n"
     ]
    }
   ],
   "source": [
    "# batch_size, epoch의 Hyperparameter 설정\n",
    "BUFFER_SIZE = len(enc_train)  # enc_train의 크기만큼 랜덤하게 섞는다.\n",
    "#BATCH_SIZE= 256\n",
    "#BATCH_SIZE= 512\n",
    "BATCH_SIZE= 128\n",
    "#BATCH_SIZE= 64\n",
    "steps_per_epoch = len(enc_train) // BATCH_SIZE\n",
    "\n",
    "VOCAB_SIZE = tokenizer.num_words + 1   # 단어 사전 크기\n",
    " # tokenizer가 구축한 단어사전 내 12000개와, 여기 포함되지 않은 0:<pad>를 포함하여 12001개\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((enc_train, dec_train)).shuffle(BUFFER_SIZE)\n",
    "# 데이터셋에 넣을때 텐서 데이터를 넣을때 순차적으로 넣는 것이 아닌 섞어서 넣겠다.\n",
    "train_dataset = train_dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "# drop_remainder : batch_size만큼 분할 했을때 해당 크기보다 작게 남은 경우\n",
    "# 마지만 남은 데이터를 drop 할 것인지 여부이다.\n",
    "\n",
    "# val_dataset 생성\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((enc_val, dec_val)).shuffle(BUFFER_SIZE)\n",
    "val_dataset = val_dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "print(\"dataset : \", train_dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM 레이어\n",
    "\n",
    "- Embedding Size와 Hidden Size를 조절하며 모델의 정확도를 높이자.\n",
    "\n",
    "\n",
    "- Embedding_size와 Hidden_size 모두 많을 수록 더 추상적인 부분과 올바른 문장을 만들겠지만, 데이터에 비례한 size보다 더 많은 size를 줄 경우 모델이 결정 내리는 것에 혼란을 줄 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 다양한 레이어 모델 구조\n",
    "---\n",
    "양방향 LSTM 사용해서 val_loss값을 줄여보자\n",
    "#### 양방향 LSTM\n",
    "- RNN이나 LSTM과 같이 데이터 길이가 길고 층이 깊으면, 과거의 정보가 손실되는 단점을 극복하기 위해 제안된 알고리즘이 **양방향 LSTM**이다.\n",
    "\n",
    "#### 양방향 LSTM 특징 :\n",
    "- 출력값에 대한 손실을 최소화 하는 과정에서 모든 파라미터가 동시에 학습되는 **종단간 학습**이 가능하다.\n",
    "\n",
    "- 단어와 구(Phrase)간 유사성을 입력벡터에 내재화하여 성능 개선\n",
    "\n",
    "- 데이터 길이가 길어도 성능이 저하되지 않는다.\n",
    "   - LSTM의 기본 성능과 Attention 매커니즘을 도입함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LSTM\n",
    "class TextGenerator(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_size):\n",
    "        super(TextGenerator, self).__init__()\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size)\n",
    "# Bidirectional LSTM : 양방향 LSTM 사용\n",
    "# 일반 RNN의 한계를 극복하기 위해 과거와 미래에 사용 가능한 모든 입력 정보를 사용하여 훈련 한다.\n",
    "# 사용 결론 : val_loss를 크게 내리긴 하지만 너무 내려서 작문이 되지 않는다.\n",
    "# val_loss값이 크게 떨어질 경우 단어가 맞는지 분류하는 것처럼 되버리게 된다.\n",
    "        #self.rnn_1 = tf.keras.layers.Bidirectional(LSTM(hidden_size, return_sequences=True))\n",
    "        self.rnn_1 = tf.keras.layers.GRU(hidden_size, return_sequences=True)\n",
    "        self.rnn_2 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.linear = tf.keras.layers.Dropout(0.3)\n",
    "        self.linear = tf.keras.layers.Dense(vocab_size)\n",
    "        \n",
    "    def call(self, x):\n",
    "        out = self.embedding(x)\n",
    "        out = self.rnn_1(out)\n",
    "        out = self.rnn_2(out)\n",
    "        out = self.linear(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "#embedding_size = 256   # 추상적 특징 잡아내는 크기\n",
    "#embedding_size = 512\n",
    "#embedding_size = 900\n",
    "#embedding_size = 300\n",
    "#embedding_size = 700\n",
    "#embedding_size = 620\n",
    "embedding_size = 512\n",
    "\n",
    "\n",
    "#hidden_size = 1024     # 모델의 올바른 결정 내리는데 도와주는 hidden state의 차원 수\n",
    "#hidden_size = 1000\n",
    "# hidden_size = 992\n",
    "#hidden_size = 1010\n",
    "#hidden_size = 520\n",
    "hidden_size = 1100\n",
    "model = TextGenerator(VOCAB_SIZE, embedding_size , hidden_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model의 입력 텐서가 무엇인지 제대로 지정해 주지도 않았을때, 아래의 코드와 같이 model에 데이터를 아주 조금 태워 보는 방법을 사용하는 방법이 있다.\n",
    "\n",
    "- model의 input shape가 결정되면서 model.build()가 자동으로 호출된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(128, 14, 13001), dtype=float32, numpy=\n",
       "array([[[ 8.3921000e-04,  7.4307295e-04,  2.5484606e-04, ...,\n",
       "          4.2757639e-04,  8.5118739e-04, -3.5672958e-04],\n",
       "        [ 1.9520106e-03,  1.1795092e-03,  2.4820093e-04, ...,\n",
       "          3.4291332e-04,  1.3984594e-03, -1.6419518e-04],\n",
       "        [ 2.8318053e-03,  1.0137106e-03, -3.0389137e-04, ...,\n",
       "         -2.6249586e-04,  9.6758711e-04,  1.0784487e-03],\n",
       "        ...,\n",
       "        [ 4.1516027e-03,  2.8585369e-04,  2.6978781e-03, ...,\n",
       "          4.1243392e-03,  1.1012789e-03,  1.1537012e-03],\n",
       "        [ 4.5398902e-03,  1.8840139e-04,  3.0711272e-03, ...,\n",
       "          4.8464108e-03,  8.4796065e-04,  1.4072109e-03],\n",
       "        [ 4.8812861e-03,  5.9723214e-05,  3.3321097e-03, ...,\n",
       "          5.4220045e-03,  5.9469737e-04,  1.6281280e-03]],\n",
       "\n",
       "       [[ 8.3921000e-04,  7.4307295e-04,  2.5484606e-04, ...,\n",
       "          4.2757639e-04,  8.5118739e-04, -3.5672958e-04],\n",
       "        [ 5.5185414e-04,  1.0835694e-04,  8.7644788e-04, ...,\n",
       "          1.3578809e-03,  1.3267773e-03, -6.6331949e-04],\n",
       "        [ 1.6777226e-04,  5.5846403e-04,  2.7466195e-03, ...,\n",
       "          2.3277968e-03,  1.8872516e-03, -6.7671546e-04],\n",
       "        ...,\n",
       "        [ 3.3750492e-03,  1.9428488e-05,  2.9703628e-03, ...,\n",
       "          2.8039140e-03,  7.6892425e-04,  7.6725142e-04],\n",
       "        [ 3.9149043e-03,  1.9736943e-05,  3.1503753e-03, ...,\n",
       "          3.6884723e-03,  7.2011794e-04,  1.1687947e-03],\n",
       "        [ 4.3868022e-03, -3.1145202e-05,  3.2898844e-03, ...,\n",
       "          4.4263080e-03,  5.9976365e-04,  1.4985582e-03]],\n",
       "\n",
       "       [[ 8.3921000e-04,  7.4307295e-04,  2.5484606e-04, ...,\n",
       "          4.2757639e-04,  8.5118739e-04, -3.5672958e-04],\n",
       "        [ 1.0028587e-03, -7.0100075e-05, -3.5672233e-04, ...,\n",
       "          1.3139283e-03,  7.7321584e-04, -7.6231384e-04],\n",
       "        [ 8.8651478e-04, -4.6227666e-04, -6.2897307e-04, ...,\n",
       "          1.7001703e-03,  1.1528574e-03, -1.2330886e-03],\n",
       "        ...,\n",
       "        [ 4.1759172e-03,  6.5944163e-04,  2.8844327e-03, ...,\n",
       "          4.7792834e-03,  9.8938053e-04,  7.1562640e-04],\n",
       "        [ 4.5958674e-03,  5.7749974e-04,  3.1421380e-03, ...,\n",
       "          5.3736172e-03,  6.9124292e-04,  1.1841643e-03],\n",
       "        [ 4.9551609e-03,  4.3424629e-04,  3.3224865e-03, ...,\n",
       "          5.8474527e-03,  4.1227660e-04,  1.5436501e-03]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 8.3921000e-04,  7.4307295e-04,  2.5484606e-04, ...,\n",
       "          4.2757639e-04,  8.5118739e-04, -3.5672958e-04],\n",
       "        [ 1.8521327e-03,  3.2859782e-04,  1.0044712e-03, ...,\n",
       "          4.2841045e-04,  1.1028190e-03, -4.9533794e-04],\n",
       "        [ 2.0896990e-03,  3.9138534e-04,  1.0061571e-03, ...,\n",
       "          2.5841731e-04,  2.2374734e-03, -1.3758526e-04],\n",
       "        ...,\n",
       "        [ 2.7693307e-03,  7.6314020e-05,  3.1444968e-03, ...,\n",
       "          1.3611196e-03,  1.7330074e-03,  4.2816749e-04],\n",
       "        [ 3.3831054e-03,  1.6104121e-04,  3.4489648e-03, ...,\n",
       "          2.6503953e-03,  1.5029437e-03,  8.6406490e-04],\n",
       "        [ 3.9150314e-03,  1.6496405e-04,  3.6471093e-03, ...,\n",
       "          3.7138686e-03,  1.2157308e-03,  1.2580678e-03]],\n",
       "\n",
       "       [[ 8.3921000e-04,  7.4307295e-04,  2.5484606e-04, ...,\n",
       "          4.2757639e-04,  8.5118739e-04, -3.5672958e-04],\n",
       "        [ 7.8225345e-04,  1.0550980e-03, -6.5512105e-04, ...,\n",
       "          3.3247002e-04,  1.0816462e-03, -1.0659828e-04],\n",
       "        [ 8.6202938e-04,  1.8586976e-03, -1.1954891e-03, ...,\n",
       "         -3.1742314e-04,  8.2407182e-04,  3.7647231e-04],\n",
       "        ...,\n",
       "        [ 1.1027369e-03, -7.5045484e-04, -1.2903330e-03, ...,\n",
       "          1.9215555e-04,  1.3734912e-03, -7.1961537e-04],\n",
       "        [ 1.7803481e-03, -7.0843863e-04, -4.0883408e-04, ...,\n",
       "          6.8729435e-04,  1.2947213e-03, -6.2303222e-04],\n",
       "        [ 2.4710118e-03, -4.8288729e-04,  4.4331799e-04, ...,\n",
       "          1.6560586e-03,  1.2275821e-03, -3.0617026e-04]],\n",
       "\n",
       "       [[ 8.3921000e-04,  7.4307295e-04,  2.5484606e-04, ...,\n",
       "          4.2757639e-04,  8.5118739e-04, -3.5672958e-04],\n",
       "        [ 7.8225345e-04,  1.0550980e-03, -6.5512105e-04, ...,\n",
       "          3.3247002e-04,  1.0816462e-03, -1.0659828e-04],\n",
       "        [ 1.6381409e-03,  9.8312425e-04, -3.4641576e-04, ...,\n",
       "         -2.3289004e-04,  1.1897230e-03, -2.1992948e-04],\n",
       "        ...,\n",
       "        [ 3.7684225e-04,  1.7641148e-03, -1.1564308e-03, ...,\n",
       "          6.8746107e-05,  7.0929754e-04,  2.5734920e-03],\n",
       "        [ 1.1502477e-04,  1.1110032e-03, -1.2585367e-03, ...,\n",
       "          4.1725868e-04,  4.3430494e-04,  2.2582596e-03],\n",
       "        [ 7.1037414e-07,  6.5605494e-04, -4.2782217e-04, ...,\n",
       "         -4.8595632e-04,  6.3196348e-04,  1.2329160e-03]]], dtype=float32)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for src_sample, tgt_sample in train_dataset.take(1): break\n",
    "model(src_sample) # 모델 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "shape=(256, 14, 12001)에서 알 수 있는 정보들 :  \n",
    "13001 : Dense 레이어의 출력 차원 수\n",
    "- 13001개의 단어 중 어느 단어의 확률이 가장 높을지를 모델링해야 하기 때문\n",
    "\n",
    "\n",
    "128 : Batch_size 값\n",
    "- dataset.take(1)를 통해서 1개의 배치, 즉 128개의 문장 데이터를 가져온 것\n",
    "\n",
    "\n",
    "14 : LSTM 레이어에서 return_sequences=True이라고 지정한 부분에 있다.\n",
    "- LSTM은 자신에게 입력된 시퀀스의 길이만큼 동일한 길이의 시퀀스를 출력한다는 의미이다.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"text_generator_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      multiple                  6656512   \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  multiple                  5326200   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                multiple                  9684400   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  14314101  \n",
      "=================================================================\n",
      "Total params: 35,981,213\n",
      "Trainable params: 35,981,213\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output Shape를 정확하게 알려주지 않는 이유 :\n",
    "현재 작사하는 인공지능 모델은 입력 시퀀스의 길이를 모르기 때문에 Output Shape를 특정할 수 없다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Loss  \n",
    "- 모델 loss 값 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "# logits 회귀 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 학습 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "import math\n",
    "epochs =10 # epochs 설정\n",
    "\n",
    "# callbacks 정의\n",
    "reduceLR = ReduceLROnPlateau(\n",
    "    monitor = 'val_loss',  # 검증 손실 기준으로 callback가 호출됨\n",
    "    #factor = 0.72,         # callback 호출시 학습률 감소\n",
    "    factor = 0.5,\n",
    "    patience= 4         # epoch 5 동안 개선되지 않을시 callback 호출\n",
    "    \n",
    ")\n",
    "\n",
    "def step_decay(epoch) :\n",
    "    initial_rate = 0.1\n",
    "    drop =0.5\n",
    "    epochs_drop=5.0\n",
    "    lrate = initial_rate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
    "    return lrate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 양방향 LSTM 사용시 과도하게 과적합 발생"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "487/487 [==============================] - 89s 184ms/step - loss: 3.3086 - val_loss: 2.9483\n",
      "Epoch 2/10\n",
      "487/487 [==============================] - 90s 185ms/step - loss: 2.8016 - val_loss: 2.7376\n",
      "Epoch 3/10\n",
      "487/487 [==============================] - 90s 186ms/step - loss: 2.5649 - val_loss: 2.5987\n",
      "Epoch 4/10\n",
      "487/487 [==============================] - 91s 186ms/step - loss: 2.3577 - val_loss: 2.4915\n",
      "Epoch 5/10\n",
      "487/487 [==============================] - 91s 186ms/step - loss: 2.1626 - val_loss: 2.4062\n",
      "Epoch 6/10\n",
      "487/487 [==============================] - 91s 186ms/step - loss: 1.9756 - val_loss: 2.3366\n",
      "Epoch 7/10\n",
      "487/487 [==============================] - 91s 187ms/step - loss: 1.7978 - val_loss: 2.2827\n",
      "Epoch 8/10\n",
      "487/487 [==============================] - 91s 186ms/step - loss: 1.6323 - val_loss: 2.2436\n",
      "Epoch 9/10\n",
      "487/487 [==============================] - 91s 187ms/step - loss: 1.4854 - val_loss: 2.2215\n",
      "Epoch 10/10\n",
      "487/487 [==============================] - 91s 187ms/step - loss: 1.3584 - val_loss: 2.2077\n"
     ]
    }
   ],
   "source": [
    "# 학습엔 10분 정도 소요된다\n",
    "\n",
    "#learning_rate =0.005\n",
    "#learning_rate =0.0035\n",
    "#learning_rate =0.004\n",
    "learning_rate =0.01\n",
    "\n",
    "decay_rate = learning_rate/10\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()  #, epsilon=1e-4)\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', patience=5)\n",
    "# patience동안 val_loss에서 개선되지 않을 시 모델 학습을 멈춘다.\n",
    "mc = ModelCheckpoint(os.getenv('HOME')+'/aiffel/lyricist/models/model_checkpoint.h5',\n",
    "                     monitor='val_loss', mode='min', \n",
    "                     save_best_only=True)\n",
    "# val_accuracy가 max값일때를 저장합니다\n",
    "\n",
    "model.compile(loss=loss, optimizer=optimizer)\n",
    "\n",
    "\n",
    "model_history = model.fit(train_dataset, epochs=10,\n",
    "                          validation_data=val_dataset,verbose=1) #, callbacks = [es, mc])\n",
    "                          #,callbacks=[reduceLR])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### val_loss 확인\n",
    "- matplotplib.pyplot의 plt 라이브러리로 결과 시각화\n",
    "\n",
    "\n",
    "- 모델 학습이 잘 되었는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "loss=model_history.history['loss']\n",
    "val_loss=model_history.history['val_loss']\n",
    "\n",
    "epochs_range = range(1,11)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, tokenizer, init_sentence=\"<start>\", max_len=14):\n",
    "    # 테스트를 위해서 입력받은 init_sentence도 일단 텐서로 변환합니다.\n",
    "    test_input = tokenizer.texts_to_sequences([init_sentence])\n",
    "    test_tensor = tf.convert_to_tensor(test_input, dtype=tf.int64)\n",
    "    end_token = tokenizer.word_index[\"<end>\"]\n",
    "\n",
    "    # 텍스트를 실제로 생성할때는 루프를 돌면서 단어 하나씩 생성해야 합니다. \n",
    "    while True:\n",
    "        predict = model(test_tensor)  # 입력받은 문장의 텐서를 입력합니다. \n",
    "        predict_word = tf.argmax(tf.nn.softmax(predict, axis=-1), axis=-1)[:, -1]   # 우리 모델이 예측한 마지막 단어가 바로 새롭게 생성한 단어가 됩니다. \n",
    "\n",
    "        # 우리 모델이 새롭게 예측한 단어를 입력 문장의 뒤에 붙여 줍니다. \n",
    "        test_tensor = tf.concat([test_tensor, \n",
    "                                 tf.expand_dims(predict_word, axis=0)], axis=-1)\n",
    "\n",
    "        # 우리 모델이 <end>를 예측했거나, max_len에 도달하지 않았다면  while 루프를 또 돌면서 다음 단어를 예측해야 합니다.\n",
    "        if predict_word.numpy()[0] == end_token: break\n",
    "        if test_tensor.shape[1] >= max_len: break\n",
    "\n",
    "    generated = \"\"\n",
    "    # 생성된 tensor 안에 있는 word index를 tokenizer.index_word 사전을 통해 실제 단어로 하나씩 변환합니다. \n",
    "    for word_index in test_tensor[0].numpy():\n",
    "        generated += tokenizer.index_word[word_index] + \" \"\n",
    "\n",
    "    return generated   # 이것이 최종적으로 모델이 생성한 자연어 문장입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> love is a beautiful thing <end> '"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> love \", max_len=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 회고\n",
    "\n",
    "- 인공지능 모델을 만들고 그 모델에게 단어를 주면 해당 단어를 시작으로 하는 노래 가사가 나온다는 것이 너무 신기했다. 지금까지는 컴퓨터가 어떠한 문제를 계산해서 분류하거나 답을 찾아내는 계산적인 부분만 했었는데 작문이라는 창작에대해서 제대로된 결과물이 나온다는 것이 너무 신기했다.\n",
    "\n",
    "\n",
    "- vla_loss값이 생각보다 더 잘안떨어지고 모델을 학습하는데 걸리는 시간도 굉장히 길어서 하는데 조금 힘이 들었지만 그래도 이 프로젝트를 진행하면서 얻어간것도 많다고 생각한다.\n",
    "\n",
    "\n",
    "- 다른 프로젝트를 했을때보다 더 많은 시간을 들이고 모델에 대해서도 더 깊이 찾아봤어서 나중에 이러한 프로젝트를 진행했을때 도움이 많이 될것 같다.\n",
    "\n",
    "\n",
    "- 양방향 LSTM과 GRU 그리고 LSTM과 GRU를 같이 결합해서 쓸때와 LSTM만 사용하는 경우 등 RNN에 대해서 많이 찾아봤고 직접 값을 조정하면서 결과를 여러번 보니 어떤 상황일때 어떤 방법이 좋겠구나 하는 것도 경험적으로 얻어간것 같다.\n",
    "\n",
    "\n",
    "- 그렇지만, 시간을 오래 사용했음에도 2.0이하의 val_loss를 얻지 못해서 아쉬움이 생기는것 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
